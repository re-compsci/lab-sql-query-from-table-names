{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        table                     definition\n",
      "0     Ramadan      A holy month for hasting \n",
      "1   John Sean                     WWE player\n",
      "2  Air Planes           flights and airports\n",
      "3        Cars  driving and companies of cars\n"
     ]
    }
   ],
   "source": [
    "#Definition of the tables.\n",
    "import pandas as pd\n",
    "\n",
    "# Table and definitions sample\n",
    "data = {'table': ['Ramadan', 'John Sean', 'Air Planes', \"Cars\"],\n",
    "        'definition':['A holy month for hasting ','WWE player', 'flights and airports', 'driving and companies of cars']\n",
    "        } # ENTER A TABLE DEFINITATIONS HERE\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ramadan: A holy month for hasting \n",
      "John Sean: WWE player\n",
      "Air Planes: flights and airports\n",
      "Cars: driving and companies of cars\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Questyion:\n",
    "{question}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [],
   "source": [
    "#Creating the prompt, with the user questions and the tables definitions.\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=f'how many days left for fasting?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"Ramadan\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 = prompt_question_tables.format(tables=text_tables,\n",
    "                                     question=\"who win?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"john sean\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d6135be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Tables\": [\n",
      "        \"Air Planes\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pqt5 = prompt_question_tables.format(tables=text_tables, question=\"my flight is in the morning, is\\'nt it?\")\n",
    "print(return_OAI(pqt5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ddd2504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Tables\": [\"Cars\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pqt6 = prompt_question_tables.format(tables=text_tables, question=\"I want more informations about elenta cars from hundai?\")\n",
    "print(return_OAI(pqt6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edf9c8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Tables\": [\"Air Planes\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pqt6 = prompt_question_tables.format(tables=text_tables, question=\"I'm going to New York\")\n",
    "print(return_OAI(pqt6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0cb5b",
   "metadata": {},
   "source": [
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The AI is very fast I\\'v tested it many times and it works very well.\n",
    "I leared a lot and I need more to precise '''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
